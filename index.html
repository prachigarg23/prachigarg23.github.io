---
layout: default
tags: about
---
<script src="https://ajax.googleapis.com/ajax/libs/jquery/3.4.1/jquery.min.js"></script>
<script type="text/javascript">
function readMore() {
    $('#readMore').hide();
    $('#more').show();
}
function readLess() {
    $('#readMore').show();
    $('#more').hide();
}
</script>

<style>
      html * {
        font-size: 13px;
      }
</style>


<img src="images/latest_me.png" alt="Prachi Garg" width="180" style="float: right; padding: 10px; border-radius: 35%;" />

<div class="bio" style="text-align:justify">

<p> Hi! I'm pursuing my Masters in Robotics at Carnegie Mellon University, where I am advised by <a href="https://www.cs.cmu.edu/~ftorre/">Prof. Fernando De La Torre</a>. I am interested in creating dynamic visual learning systems that continuously adapt and generalise to unseen concepts, particularly from a life-long and low-shot learning perspective. </p>
  <!-- I have been closely collaborating with <a href="https://www.iith.ac.in/~vineethnb/">Prof. Vineeth N B</a> and <a href="https://josephkj.in/">Joseph K J</a>, along with <a href="https://shugaoma.github.io/">Shugao Ma</a>, <a href="https://www.cihancamgoz.com/">Necati Cihan Camgoz</a>, <a href="https://www.linkedin.com/in/kenrick-kin-51575753">Kenrick Kin</a>, <a href="https://scholar.google.ch/citations?user=bm5dZwIAAAAJ&hl=en">Chengde Wan</a> and
<a href="https://scholar.google.com/citations?user=QivUtBIAAAAJ&hl=en">Weiguang Si</a> from Meta Reality Labs, working on continual, open vocabulary human action recognition for XR applications. -->

<p>Previously, I spent two wonderful years working as a Research Fellow with <a href="https://faculty.iiit.ac.in/~jawahar/">Prof. C V Jawahar</a>, and jointly co-advised by <a href="https://www.iith.ac.in/~vineethnb/">Prof. Vineeth N Balasubramanian</a>, <a href="https://www.cse.iitd.ac.in/~chetan/">Prof. Chetan Arora</a> and <a href="https://scholar.google.co.in/citations?user=s1Xm-NsAAAAJ&hl=en">Dr. Anbumani Subramanian</a>, working on Continual Semantic Segmentation for Autonomous Driving. In summer 2019, an opportunity to conduct research with <a href="https://scholar.google.com/citations?hl=en&user=Gb5a92sAAAAJ&view_op=list_works&sortby=pubdate">Prof. Frederic Jurie</a> in beautiful Normandy (France) made me want to pursue research long term!
  <!-- I completed my Bachelors in Computer Science and Engineering in 2020 from Delhi College of Engineering, India. -->
</p>
<br>
<p>
<!-- Even before, I've had the pleasure of conducting research at:
<ul>
  <li>
    <p><a href="https://research.ibm.com/">IBM Research AI</a>, summer 2020 with <a href="https://researcher.watson.ibm.com/researcher/view.php?person=in-sameepmehta">Dr. Sameep Mehta</a> and <a href="https://researcher.watson.ibm.com/researcher/view.php?person=in-nishthamadaan">Nishtha Madaan</a>.</p>
  </li>
  <li>
    <p>Bachelors thesis project advised by <a href="https://dtu.irins.org/profile/66871#personal_information_panel">Prof. Rajni Jindal</a>. I was curious about geometric deep learning and explored multi-label node classification using GNNs.
  </li>
  <li>
    <p><a href="https://www.greyc.fr/en/home/">Image Team GREYC</a>, <a href="https://www.unicaen.fr/">University of Caen Normandy</a>, <a href="http://www.cnrs.fr/">CNRS</a> (France), summer 2019 with <a href="https://scholar.google.com/citations?hl=en&user=Gb5a92sAAAAJ&view_op=list_works&sortby=pubdate">Prof. Frederic Jurie</a> and <a href="https://lechervy.users.greyc.fr/index.php#">Prof. Alexis Lechervy</a>. This summer spent doing research with Prof. Frederic Jurie in beautiful Normandy (France) made me want to pursue research long term!</p>
  </li>
  <li>
    <p><a href="https://www.iiitd.ac.in/">IIITD</a>, in my 3rd year of Bachelors with <a href="https://www.iiitd.ac.in/anands">Prof. Saket Anand</a>. I had the opportunity to work on Domain Generalization for Animal Detection on the Caltech Camera Traps Dataset (for visual wildlife monitoring applications).
    </p>
  </li>
</ul> -->
</p>

<!-- <p><strong>Research Interests: <span style="color:gray">I'm interested in studying how deep neural networks can be made to generalize well to novel environments and visual scenes. My areas of interest include continual (life-long) and meta learning, domain adaptation, improving generalization in neural networks, multi-task learning and visual scene understanding. I'm excited about autonomous driving and aerial robotics. I find geometric deep learning and graph neural networks to be really fascinating. I'm attracted towards challenging AI applications with a social impact.</p></span></strong> -->

<!-- <p>I love books and cinema, so much that I often find myself tracing movies back to their cast and analysing them. I enjoy cycling and (try) dancing in my free time. Iâ€™m always up for interesting collaborations or just random chats on AI, feel free to drop me a message on Linkedin or via email.</p> -->

<br/>

<!-- <div class="container">
  <div class="row" style="text-align:center;">
        <div class="col">
          <a href="https://www.ri.cmu.edu/"><img src="images/cmu.png" style="max-height:150px;width:80%"></a>
        </div>
        <div class="col">
          <a href="http://dtu.ac.in/"><img src="images/dtu.png" style="max-height:150px;width:80%"></a>
        </div>
        <div class="col" style="text-align:center;">
          <a href="https://www.iiit.ac.in/"><img src="images/IIITH.png" style="max-height:150px;width:80%"></a>
        </div>
        <div class="col" style="text-align:center;">
          <a href="https://research.ibm.com/"><img src="images/ibm.png" style="width:80%;max-height:150px"></a>
        </div>
        <div class="col">
          <a href="https://www.ensicaen.fr/en/research/greyc/"><img src="images/greyc.png" style="width:80%;max-height:150px"></a>
        </div>
        <div class="col">
          <a href="https://www.iiitd.ac.in/"><img src="images/IIITD.png" style="width:80%;max-height:150px"></a>
        </div>
  </div>
  <div class="row" style="text-align:center;">
        <div class="col">
          <div style="padding:10px"><h6>2022-Present</h6></div>
        </div>
        <div class="col">
          <div style="padding:10px"><h6>2016-2020</h6></div>
        </div>
        <div class="col">
          <div style="padding:10px"><h6>2020-2022</h6></div>
        </div>
        <div class="col">
          <div style="padding:10px"><h6>Summer 2020</h6></div>
        </div>
        <div class="col">
          <div style="padding:10px"><h6>Summer 2019</h6></div>
        </div>
        <div class="col">
          <div style="padding:10px"><h6>Winter 2018</h6></div>
        </div>
  </div>
</div> -->

<!-- <hr/> -->
<br/>

<div id="research">
<h2><a name="research">Recent Publications</a></h2>
<br/>

<table width="100%" align="center" valign="middle" cellspacing="0" cellpadding="0" style="border-collapse: collapse;">
    <tbody>
      <tr>
      <td width="35%">
        <div class="one" style="text-align:center;">
            <img src="images/poet_teaser.png" style="max-height: 350px;">
        </div>
      </td>
      <td valign="top" width="65%">
        <h5>
        Continual Few-Shot Learning of New Actions With Prompt Tuning
        </h5>
        <p class="authors">
        <font size="-2"><b>Prachi Garg</b>, Joseph K J, Vineeth N B, Necati Cihan Camgoz, Chengde Wan, Kenrick Kin, Weiguang Si, Shugao Ma, Fernando De la Torre</font>
        </p>
        <p>
        Under Review, 2024
        </p>
        <p>
        Continual personalisation without forgetting of human action and hand gesture recognition. We enable users in a XR device to add new classes in a few-shot continual manner, while preserving user privacy. We show that prompt tuning of lightweight non-transformer backbones (such as GCNs) can be used to solve this problem!
        <!-- <a href="https://openaccess.thecvf.com/content/WACV2022/papers/Garg_Multi-Domain_Incremental_Learning_for_Semantic_Segmentation_WACV_2022_paper.pdf">Paper / </a>
        <! <i><a href="https://arxiv.org/abs/2110.12205">arxiv / </a></i> -->
        <!-- <a href="https://www.youtube.com/watch?v=YQC5KLZUpyc">Video / </a>
        <a href="https://github.com/prachigarg23/MDIL-SS">Code / </a>
        <a href="reports/294-wacv-poster.pdf">Poster / </a>
        <a href="https://openaccess.thecvf.com/content/WACV2022/supplemental/Garg_Multi-Domain_Incremental_Learning_WACV_2022_supplemental.pdf">Supplementary</a> -->
        </p>

      </td>
    </tr>
    <tr>
    <td width="35%">
      <div class="one" style="text-align:center;">
          <img src="images/ICCV2023_BOATMI.png" style="max-height: 350px;">
      </div>
    </td>
    <td valign="top" width="65%">
      <h5>
      Data-Free Class-Incremental Hand Gesture Recognition
      </h5>
      <p class="authors">
      <font size="-2">Shubhra Aich*, Jesus Ruiz*, Zhenyu Lu, <b>Prachi Garg</b>, K J Joseph, Alvaro Garcia, Vineeth N B, Kenrick Kin, Chengde Wan, Necati Cihan Camgoz, Shugao Ma, Fernando De La Torre</font>

      </p>
      <p>
      ICCV 2023
      </p>
      <p>
      <a href="https://openaccess.thecvf.com/content/ICCV2023/papers/Aich_Data-Free_Class-Incremental_Hand_Gesture_Recognition_ICCV_2023_paper.pdf">Paper / </a>
      <a href="https://github.com/humansensinglab/dfcil-hgr">Code </a>
      </p>

    </td>
  </tr>
      <tr>
      <td width="35%">
        <div class="one" style="text-align:center;">
            <img src="images/maindiagram.png" style="max-height: 350px;">
        </div>
      </td>
      <td valign="top" width="65%">
        <h5>
        Multi-Domain Incremental Learning for Semantic Segmentation
        </h5>
        <p class="authors">
        <font size="-2"><b>Prachi Garg</b>, Rohit Saluja, Vineeth N B, Chetan Arora, Anbumani Subramanian, C V Jawahar</font>
        </p>
        <p>
        WACV 2022
        </p>
        <p>
        <a href="https://openaccess.thecvf.com/content/WACV2022/papers/Garg_Multi-Domain_Incremental_Learning_for_Semantic_Segmentation_WACV_2022_paper.pdf">Paper / </a>
        <!-- <i><a href="https://arxiv.org/abs/2110.12205">arxiv / </a></i> -->
        <a href="https://www.youtube.com/watch?v=YQC5KLZUpyc">Video / </a>
        <a href="https://github.com/prachigarg23/MDIL-SS">Code / </a>
        <a href="reports/294-wacv-poster.pdf">Poster / </a>
        <a href="https://openaccess.thecvf.com/content/WACV2022/supplemental/Garg_Multi-Domain_Incremental_Learning_WACV_2022_supplemental.pdf">Supplementary</a>
        </p>

      </td>
    </tr>
  </tbody>
</table>
</div>

<br/>

<div id="research projects">
<h2><a name="research">Selected Research Projects</a></h2>
<br/>

<table width="100%" align="center" valign="middle" cellspacing="0" cellpadding="0" style="border-collapse: collapse;">
    <tbody>
    <tr>
    <td width="35%">
      <div class="one" style="text-align:center;">
          <img src="images/diagram-ibm.png" style="max-height: 200px;">
      </div>
    </td>
    <td valign="top" width="65%">
      <h5>
      Towards an AI Infused System for Objectionable Content Detection in OTT
      </h5>
      <p class="authors">
      <font size="-2"> <b>Prachi Garg</b>, Shivang Chopra, Mudit Saxena, Anshu Yadav, Aditya Atri, Nishtha Madaan, Sameep Mehta</font>

      </p>
      <p>
        <a href="https://www.linkedin.com/pulse/towards-ai-infused-system-personalization-video-content-madaan/?articleId=6699399357223218177">Blog-post / </a>
        <a href="https://drive.google.com/drive/folders/1DVUCCE7OLlA7nFbgsf3VanIH_pZRprrq?usp=sharing">Demo </a>
        <!-- <a href="https://kidify-ibm.herokuapp.com/survey.html">Survey</a> -->
      </p>
      <p>With the substantial increase in the consumption of OTT content in recent years, personalized objectionable content detection and filtering has become pertinent for making movie and TV series content suitable for family or children viewing. We propose an objectionable content detection framework which leverages multiple modalities like (i) videos, (ii) subtitle text and (iii) audio to detect (a) violence, (b) explicit NSFW content, and (c) offensive speech in videos. </p>
      <!-- <a href="https://www.linkedin.com/pulse/towards-ai-infused-system-personalization-video-content-madaan/?articleId=6699399357223218177" class="btn btn-outline-primary btn-sm" role="button" aria-pressed="true">Blog-post</a>
      <a href="https://drive.google.com/drive/folders/1DVUCCE7OLlA7nFbgsf3VanIH_pZRprrq?usp=sharing" class="btn btn-outline-primary btn-sm" role="button" aria-pressed="true">Demo</a>
      <a href="https://kidify-ibm.herokuapp.com/survey.html" class="btn btn-outline-primary btn-sm" role="button" aria-pressed="true">Survey</a> -->
    </td>
  </tr>
  <tr>
  <td width="35%">
    <div class="one" style="text-align:center;">
        <img src="images/greyc-proposed-model.png" style="max-height: 200px;">
    </div>
  </td>
  <td valign="top" width="65%">
    <h5>
    Memorization and Generalization in CNNs using Soft Gating Mechanisms
    </h5>
    <p class="authors">
    <font size="-2"><b>Prachi Garg</b>, Shivang Agarwal, Alexis Lechervy, Frederic Jurie</font>
    </p>
    <p>
    <a href="reports/Report-GREYC.pdf">Technical Report / </a>
    <a href="https://github.com/prachigarg23/Memorisation-and-Generalisation-in-Deep-CNNs-Using-Soft-Gating-Mechanisms">Code / </a>
    <a href="reports/report-failed-models-GREYC.pdf">Technical Report, Suboptimal ResNet Gating Mechanisms</a>
    </p>
    <p>A deep neural network learns patterns to hypothesize a large subset of samples that lie in-distribution and it memorises any out-of-distribution samples. While fitting to noise, the generalisation error increases and the DNN performs poorly on test set. In this work, we aim to examine if dedicating different layers to the generalizable and memorizable samples in a DNN could simplify the decision boundary learnt by the network and lead to improved generalization in DNNs. While the initial layers that are common to all examples tend to learn general patterns, we dedicate certain deeper additional layers in the network to memorise the out-of-distribution examples.</p>
    <!-- <a href="reports/Report-GREYC.pdf" class="btn btn-outline-primary btn-sm" role="button" aria-pressed="true">Report</a>
    <a href="https://github.com/prachigarg23/Memorisation-and-Generalisation-in-Deep-CNNs-Using-Soft-Gating-Mechanisms" class="btn btn-outline-primary btn-sm" role="button" aria-pressed="true">Code</a>
    <a href="reports/report-failed-models-GREYC.pdf" class="btn btn-outline-primary btn-sm" role="button" aria-pressed="true">Suboptimal ResNet Gating Mechanisms</a> -->
  </td>
  </tr>
  </tbody>
</table>
</div>

<!-- ML-GAT: Multi-label Node Classification using Enhanced Graph Attention Network
Prachi Garg*, Ashi Gupta*, Rajni Jindal

Many real-world graph based problems require the assignment of more than one label to each node instance in the graph. We study here multi-label node classification using enhanced graph neural networks. We propose a novel architecture, Multi-Label Graph attention Network (ML-GAT) that leverages the applicability of the attention based Graph Attention Network (GAT) to efficient inductive semi-supervised multi-label classification by augmenting complex inter-label and node-label dependencies implicit in the graph structure to the learning process. Our model achieves 15.01% increase over the current state-of-the-art ML-GCN framework for Facebook dataset and 6% increase for the Yeast dataset. We analyse the influence of dropout and training size; and infer the relative importance of node-label and label-label dependencies.

*Denotes equal contribution -->

<!-- Visual Wildlife Monitoring: Domain Generalization for Animal Detection in the Wild
Prachi Garg, Gullal Cheema, Saket Anand

I worked towards benchmarking species detection in camera trap images from unconstrained wild environments to generalise to new environments using state-of-the-art Faster-RCNN variants. The Catech Camera Traps dataset (CCT20) is an unconstrained wild environment camera traps dataset designed to study domain generalization for animal species. It contains test data collected from both, locations that are same as train data (cis) as well as locations different from train data (trans). Factors like illumination, motion blur, occlusion, camouflage and perspective can severely affect the performance of species recognition systems. We bridged the generalization gap between cis-locations (test domain same as train) and trans-locations (unseen test domain) performance from 26.8% to 22.9% by using state-of-the-art Faster-RCNN variants. -->

<!-- <div id="talks">
<h2>News and Miscellaneous</h2>
<table width="100%" align="center" valign="middle" cellspacing="0" cellpadding="0" style="border-collapse: collapse;">
    <tbody>
      <tr>
      <td width="20%">
        <h5>
          January, 2022
        </h5>
      </td>
      <td valign="middle" width="80%">
        <h5>
        Presented our work on 'Multi-domain incremental learning for semantic segmentation' at WACV 2022
        </h5>
      </td>
      </tr>
      <tr>
      <td width="20%">
        <h5>
          December, 2021
        </h5>
      </td>
      <td valign="middle" width="80%">
        <h5>
        Funded to be a Super Volunteer, WiML Workshop @ NeurIPS 2021; Attended NeurIPS 2021 Workshop on Machine Learning for Autonomous Driving
        </h5>
      </td>
      </tr>
      <tr>
      <td width="20%">
        <h5>
          August, 2021
        </h5>
      </td>
      <td valign="middle" width="80%">
        <h5>
        Sub Reviewer, BMVC 2021
        </h5>
      </td>
      </tr>
      <tr>
      <td width="20%">
        <h5>
          September, 2020
        </h5>
      </td>
      <td valign="middle" width="80%">
        <h5>
        Gave a tutorial on Geometric Deep Learning and Graph Convolutional Networks (GCN)
        </h5>
        <p class="authors">
        Reading Group: Vision for Mobility and Safety
        <br>
        <a href="reports/GCN-Tutorial-Wed-meeting.pdf">Slides</a>
        </p>
      </td>
      </tr>
  </tbody>
</table>
</div> -->

<!-- <p> I have also worked on Domain Generalization in Animal Detection for visual wiildlife monitoring, and multi-label node classification in Graph Attention Networks.</p> -->
<hr>
<p align="right">
<small>Forked and modified from <a href="https://virajprabhu.github.io/">Viraj Prabhu's</a> adaptation of <a href="https://github.com/johno/pixyll">Pixyll</a> theme</a></small></p>
